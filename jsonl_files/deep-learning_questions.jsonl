{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the purpose of the activation function in a neural network?","options":{"A":"To reduce overfitting","B":"To normalize the data","C":"To initialize the weights","D":"To add non-linearity to the model"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which of the following activation functions is commonly used in neural networks?","options":{"A":"ReLU","B":"All of the above","C":"Tanh","D":"Sigmoid"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is a neuron in the context of neural networks?","options":{"A":"A loss function","B":"None of the above","C":"A data storage unit","D":"A unit of computation that applies a linear transformation followed by an activation function"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which of the following is a common loss function used in neural networks?","options":{"A":"Hinge Loss","B":"Cross-Entropy Loss","C":"All of the above","D":"Mean Squared Error"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the primary purpose of a convolutional layer in a CNN?","options":{"A":"To detect spatial features in input data","B":"To normalize data","C":"To reduce the dimensionality of data","D":"To perform linear regression"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which of the following techniques is used to prevent overfitting in neural networks?","options":{"A":"All of the above","B":"Batch Normalization","C":"Early Stopping","D":"Dropout"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is backpropagation?","options":{"A":"A method to initialize the weights","B":"A technique to compute the gradient of the loss function with respect to each weight","C":"A regularization technique","D":"A way to normalize the input data"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which of the following is true about the ReLU activation function?","options":{"A":"It can suffer from the dying ReLU problem","B":"It is computationally efficient","C":"All of the above","D":"It can introduce sparsity in the activations"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the vanishing gradient problem?","options":{"A":"When the gradients become very small, making it difficult for the model to learn","B":"When the gradients become very large, causing the model to diverge","C":"None of the above","D":"When the model overfits the training data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the purpose of the softmax function?","options":{"A":"To add non-linearity to the model","B":"To initialize the weights","C":"To reduce overfitting","D":"To normalize the output to a probability distribution"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of the pooling layer in a CNN?","options":{"A":"To reduce the dimensionality of the input","B":"To normalize the input data","C":"To increase the computational complexity","D":"To add non-linearity to the model"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of batch normalization?","options":{"A":"To initialize the weights","B":"To normalize the input features of each batch","C":"To increase the learning rate","D":"To prevent overfitting"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of the LSTM layer in a neural network?","options":{"A":"To add non-linearity to the model","B":"To capture long-term dependencies in sequence data","C":"To normalize the input data","D":"To reduce the dimensionality of the input data"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which of the following is true about the dropout technique?","options":{"A":"It increases the learning rate","B":"It reduces overfitting by randomly setting a fraction of the activations to zero during training","C":"It normalizes the input data","D":"It reduces the dimensionality of the input data"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of the cross-entropy loss function?","options":{"A":"To normalize the input data","B":"To initialize the weights","C":"To measure the performance of a classification model","D":"To measure the performance of a regression model"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which of the following is a characteristic of the tanh activation function?","options":{"A":"It suffers from the vanishing gradient problem","B":"It is computationally expensive","C":"It outputs values between 0 and 1","D":"It outputs values between -1 and 1"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the primary purpose of using an embedding layer in a neural network?","options":{"A":"To transform categorical data into a continuous vector space","B":"To reduce the dimensionality of the input data","C":"To add non-linearity to the model","D":"To normalize the input data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which of the following is true about the gradient clipping technique?","options":{"A":"It normalizes the input data","B":"It prevents the gradients from becoming too large","C":"It increases the learning rate","D":"It reduces overfitting by adding a penalty to the loss function"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of using a recurrent neural network (RNN)?","options":{"A":"To process fixed-length input data","B":"To reduce the dimensionality of the input data","C":"To process sequential data","D":"To normalize the input data"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which of the following is true about the Adam optimizer?","options":{"A":"It requires less memory","B":"It combines the advantages of both AdaGrad and RMSProp","C":"All of the above","D":"It performs well with sparse gradients"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the batch normalization technique?","options":{"A":"It normalizes the input data","B":"It increases the learning rate","C":"It reduces overfitting","D":"It accelerates the training process by reducing internal covariate shift"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the purpose of the attention mechanism in neural networks?","options":{"A":"To focus on relevant parts of the input sequence","B":"To reduce the dimensionality of the input data","C":"To normalize the input data","D":"To increase the learning rate"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"Which of the following is true about the gated recurrent unit (GRU)?","options":{"A":"All of the above","B":"It has fewer parameters compared to LSTM","C":"It does not suffer from the vanishing gradient problem","D":"It is a type of RNN that can capture long-term dependencies"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the ReLU activation function?","options":{"A":"It avoids the vanishing gradient problem","B":"It is computationally efficient","C":"All of the above","D":"It adds non-linearity to the model"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the purpose of using the softmax function in the output layer of a neural network?","options":{"A":"To add non-linearity to the model","B":"To normalize the output to a probability distribution","C":"To initialize the weights","D":"To reduce overfitting"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the dropout technique in neural networks?","options":{"A":"It increases the learning rate","B":"It normalizes the input data","C":"It reduces the dimensionality of the input data","D":"It reduces overfitting by randomly setting a fraction of the activations to zero during training"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the Adam optimizer?","options":{"A":"It performs well with sparse gradients","B":"It combines the advantages of both AdaGrad and RMSProp","C":"It requires less memory","D":"All of the above"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the max-pooling layer in a CNN?","options":{"A":"To reduce the dimensionality of the input data","B":"To normalize the input data","C":"To add non-linearity to the model","D":"To increase the dimensionality of the input data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the gated recurrent unit (GRU)?","options":{"A":"All of the above","B":"It is a type of RNN that can capture long-term dependencies","C":"It does not suffer from the vanishing gradient problem","D":"It has fewer parameters compared to LSTM"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the main advantage of using the attention mechanism in neural networks?","options":{"A":"It normalizes the input data","B":"It reduces the dimensionality of the input data","C":"It increases the learning rate","D":"It focuses on relevant parts of the input sequence"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the role of a perceptron in a neural network?","options":{"A":"To sort data","B":"To aggregate input features linearly","C":"To compress data","D":"To encrypt data"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which of the following best describes the perceptron learning rule?","options":{"A":"Increase weights for every input","B":"Decrease weights for every input","C":"Adjust weights based on the difference between the predicted and actual output","D":"Keep weights constant"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which activation function would you use to introduce non-linearity in a neural network?","options":{"A":"Linear","B":"ReLU","C":"Binary Step","D":"Identity"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"How do you implement the ReLU activation function in Python?","options":{"A":"def relu(x): return np.minimum(0, x)","B":"def relu(x): return np.abs(x)","C":"def relu(x): return x**2","D":"def relu(x): return np.maximum(0, x)"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the derivative of the sigmoid activation function used for backpropagation?","options":{"A":"sigmoid(x) * (1 - sigmoid(x))","B":"x * (1 - x)","C":"sigmoid(x)","D":"1 - sigmoid(x)"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of a loss function in neural networks?","options":{"A":"To measure the difference between the predicted and actual output","B":"To compress data","C":"To sort data","D":"To encrypt data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which loss function is commonly used for binary classification?","options":{"A":"Categorical Cross-Entropy","B":"Mean Squared Error","C":"Hinge Loss","D":"Binary Cross-Entropy"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"How do you implement the binary cross-entropy loss function in Python?","options":{"A":"def binary_cross_entropy(y_true, y_pred): return np.sum(np.square(y_true - y_pred))","B":"def binary_cross_entropy(y_true, y_pred): return np.mean(np.square(y_true - y_pred))","C":"def binary_cross_entropy(y_true, y_pred): epsilon = 1e-15 y_pred = np.clip(y_pred, epsilon, 1 - epsilon) return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))","D":"def binary_cross_entropy(y_true, y_pred): return np.mean(np.abs(y_true - y_pred))"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the purpose of backpropagation in neural networks?","options":{"A":"To encrypt data","B":"To sort data","C":"To compress data","D":"To update the weights of the network by propagating the error gradient backward"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"How is the gradient of the loss with respect to weights calculated in backpropagation?","options":{"A":"By summing the weights","B":"By multiplying the weights","C":"By averaging the weights","D":"By applying the chain rule of calculus"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"How do you implement the gradient descent algorithm in Python?","options":{"A":"def gradient_descent(X, y, weights, learning_rate, iterations): m = len(y) for i in range(iterations): error = np.dot(X, weights) gradients = np.dot(X.T, error) \/ m weights -= learning_rate * gradients return weights","B":"def gradient_descent(X, y, weights, learning_rate, iterations): m = len(y) for i in range(iterations): gradients = np.dot(X.T, y) \/ m weights += learning_rate * gradients return weights","C":"def gradient_descent(X, y, weights, learning_rate, iterations): m = len(y) for i in range(iterations): predictions = np.dot(X, weights) error = predictions - y gradients = np.dot(X.T, error) \/ m weights -= learning_rate * gradients return weights","D":"def gradient_descent(X, y, weights, learning_rate, iterations): m = len(y) for i in range(iterations): error = np.dot(X, weights) gradients = np.dot(X.T, error) \/ m weights *= learning_rate * gradients return weights"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the main purpose of regularization in neural networks?","options":{"A":"To prevent overfitting","B":"To sort data","C":"To encrypt data","D":"To compress data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which regularization technique involves adding a penalty proportional to the absolute value of the weights?","options":{"A":"Dropout","B":"Early Stopping","C":"L1 Regularization","D":"L2 Regularization"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"How do you implement L2 regularization in the loss function?","options":{"A":"def l2_regularization_loss(weights, lambda_): return lambda_ * np.mean(np.abs(weights))","B":"def l2_regularization_loss(weights, lambda_): return lambda_ * np.sum(np.abs(weights))","C":"def l2_regularization_loss(weights, lambda_): return lambda_ * np.sum(np.square(weights))","D":"def l2_regularization_loss(weights, lambda_): return lambda_ * np.mean(np.square(weights))"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the purpose of an activation function in a neural network?","options":{"A":"To introduce non-linearity into the network","B":"To sort data","C":"To compress data","D":"To encrypt data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"Which of the following is a commonly used activation function in neural networks?","options":{"A":"Step","B":"Linear","C":"Exponential","D":"ReLU"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"How do you implement the sigmoid activation function in Python?","options":{"A":"def sigmoid(x): return np.tanh(x)","B":"def sigmoid(x): return 1 \/ (1 + np.exp(-x))","C":"def sigmoid(x): return np.exp(x) \/ (1 + np.exp(x))","D":"def sigmoid(x): return x \/ (1 + np.abs(x))"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"How do you implement the mean squared error (MSE) loss function in Python?","options":{"A":"def mse(y_true, y_pred): return np.sum((y_true - y_pred)**2)","B":"def mse(y_true, y_pred): return np.mean(np.abs(y_true - y_pred))","C":"def mse(y_true, y_pred): return np.mean((y_true - y_pred)**2)","D":"def mse(y_true, y_pred): return np.abs(y_true - y_pred)"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"How does the learning rate affect the training of a neural network?","options":{"A":"It compresses the data","B":"It determines the step size for updating weights","C":"It sorts the data","D":"It encrypts the data"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is a common issue when the learning rate is set too high?","options":{"A":"The model may diverge and fail to converge","B":"The model may encrypt data","C":"The model may learn too quickly","D":"The model may compress data inefficiently"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the role of a loss function in training neural networks?","options":{"A":"To sort the training data","B":"To measure how well the model's predictions match the actual outcomes","C":"To compress the input data","D":"To encrypt the model weights"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which of the following is an example of a non-linear activation function?","options":{"A":"Binary Step","B":"Identity","C":"Linear","D":"ReLU"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"How do you implement the softmax function in Python?","options":{"A":"def softmax(x): return np.tanh(x)","B":"def softmax(x): return np.log(x)","C":"def softmax(x): return x \/ np.sum(x)","D":"def softmax(x): exps = np.exp(x - np.max(x)) return exps \/ np.sum(exps, axis=0)"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the primary difference between batch gradient descent and stochastic gradient descent (SGD)?","options":{"A":"Batch gradient descent uses the entire dataset to compute gradients, while SGD uses one sample at a time","B":"Batch gradient descent is faster than SGD","C":"Batch gradient descent compresses data, while SGD scales data","D":"Batch gradient descent sorts data, while SGD encrypts data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is the purpose of dropout in training neural networks?","options":{"A":"To prevent overfitting by randomly dropping units during training","B":"To encrypt data","C":"To compress data","D":"To sort data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What is a hyperparameter in the context of neural networks?","options":{"A":"A type of activation function","B":"A type of loss function","C":"A parameter whose value is set before the learning process begins","D":"A parameter learned from the data"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"Which of the following is NOT a common activation function?","options":{"A":"Sigmoid","B":"Softmax","C":"Fourier","D":"ReLU"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"Which optimization algorithm is known for its ability to adapt the learning rate of each parameter?","options":{"A":"Adagrad","B":"RMSprop","C":"Adam","D":"SGD"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is a common technique to mitigate the vanishing gradient problem?","options":{"A":"Using larger batch sizes","B":"Decreasing the learning rate","C":"Using linear activation functions","D":"Using ReLU activation functions"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"easy","type":"multiple_choice","question":"What does the term 'epoch' refer to in training neural networks?","options":{"A":"One update of weights","B":"One mini-batch of data","C":"One gradient calculation","D":"One complete pass through the entire training dataset"},"correct_answers":["D"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the purpose of a validation set in training neural networks?","options":{"A":"To evaluate the model's performance on unseen data during training","B":"To encrypt the model weights","C":"To sort the training data","D":"To compress the input data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the primary goal of early stopping in neural network training?","options":{"A":"To increase training speed","B":"To compress the input data","C":"To prevent overfitting by stopping training when performance on a validation set decreases","D":"To encrypt the model weights"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"Which type of neural network is most suitable for processing sequential data?","options":{"A":"Radial Basis Function Network (RBFN)","B":"Recurrent Neural Network (RNN)","C":"Convolutional Neural Network (CNN)","D":"Fully Connected Network (FCN)"},"correct_answers":["B"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"What is the purpose of using a learning rate scheduler during training?","options":{"A":"To adjust the learning rate dynamically based on the training process","B":"To sort the training data","C":"To encrypt the model weights","D":"To compress the input data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"How does batch normalization help in training deep neural networks?","options":{"A":"By normalizing the inputs of each layer, it reduces internal covariate shift","B":"By compressing the input data","C":"By encrypting the model weights","D":"By sorting the training data"},"correct_answers":["A"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"hard","type":"multiple_choice","question":"Which of the following is a common method to initialize the weights of a neural network?","options":{"A":"Symmetric Initialization","B":"Zero Initialization","C":"Xavier Initialization","D":"Binary Initialization"},"correct_answers":["C"],"is_multiple_choice":false}
{"skill":"Neural Networks","difficulty":"medium","type":"multiple_choice","question":"What is the main advantage of using convolutional layers in neural networks?","options":{"A":"They compress the input data","B":"They are able to capture spatial hierarchies in data","C":"They encrypt the model weights","D":"They sort the input data"},"correct_answers":["B"],"is_multiple_choice":false}
